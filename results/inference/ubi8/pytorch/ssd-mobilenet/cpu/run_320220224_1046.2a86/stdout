/home/ahalwai/mlperf-inference/mlperf/inference/vision/classification_and_detection
script: |/home/ahalwai/matrix-benchmarking/../mlperf-inference/mlperf/inference/vision/classification_and_detection/run_and_time_ubi8.sh| frame:|pytorch| model:|ssd-mobilenet| device:|cpu|
STEP 1/19: FROM registry.access.redhat.com/ubi8/ubi
STEP 2/19: ENV PYTHON_VERSION=3.7
--> Using cache 4abe5ae5f1443c8c0fb1bad5b3ee61b698f1ea1cd0bc959a595377b0e236a335
--> 4abe5ae5f14
STEP 3/19: ENV LANG C.UTF-8
--> Using cache 695ef18b9bad45a62801f08eb00a65d11c726ed31fb97d7cb8baf39b87640228
--> 695ef18b9ba
STEP 4/19: ENV LC_ALL C.UTF-8
--> Using cache 9c03ab6ae3b9e2baaf2912f03a87098fd9ad5a9f19288b594eb8b7a14b4e2978
--> 9c03ab6ae3b
STEP 5/19: ENV PATH /opt/anaconda3/bin:$PATH
--> Using cache dd6f35561101d5428d9d144b06de7ae6209fda18c3c606ac3175fcec22379d8f
--> dd6f3556110
STEP 6/19: WORKDIR /root
--> Using cache 426aeaa444c20410352f15c8633bc86ae1470774b5c32a4e8e4f9f67ebf74697
--> 426aeaa444c
STEP 7/19: ENV HOME /root
--> Using cache a4ff533090d6963a48ba9b0e0448d2456f81429648fa0fa24fcddeeb25f6861b
--> a4ff533090d
STEP 8/19: RUN dnf clean all
--> Using cache 408819747b07c50c092c441a74959e9fcc005dc6c6153c294a64218b486e322e
--> 408819747b0
STEP 9/19: RUN dnf -y update
--> Using cache e09f54a42939f3cbe1034caef2688be1097759c163690d4c4f97a8daebbc4202
--> e09f54a4293
STEP 10/19: RUN dnf install -y       https://dl.fedoraproject.org/pub/epel/epel-release-latest-8.noarch.rpm       git       gcc-c++ kernel-devel make       ca-certificates       wget       curl       htop       zip       unzip       bzip2
--> Using cache f5e8b03d3d9671f2f406db6efe148a90294f6507528d9b79e3a34210bc7252c7
--> f5e8b03d3d9
STEP 11/19: RUN cd /opt &&     wget --quiet https://repo.anaconda.com/miniconda/Miniconda3-4.6.14-Linux-x86_64.sh -O miniconda.sh &&     /bin/bash ./miniconda.sh -b -p /opt/anaconda3 &&     rm miniconda.sh &&     /opt/anaconda3/bin/conda clean -tipsy &&     ln -s /opt/anaconda3/etc/profile.d/conda.sh /etc/profile.d/conda.sh &&     echo ". /opt/anaconda3/etc/profile.d/conda.sh" >> ~/.bashrc &&     echo "conda activate base" >> ~/.bashrc &&     conda config --set always_yes yes --set changeps1 no
--> Using cache a68551bb4f65ceb4cadf6139f1afba0057a262c82d776d014857619bf3006931
--> a68551bb4f6
STEP 12/19: RUN conda install pytorch-cpu torchvision-cpu -c pytorch
--> Using cache e57dcc222d402ab078445a5984b4c72880a9766b2ff3b6381cedf1c39d3de201
--> e57dcc222d4
STEP 13/19: RUN pip install --upgrade pip setuptools wheel
--> Using cache fb67922c78f678e1d9dd29300e60130d0ff521d3578c387d01c984bbd7d822b6
--> fb67922c78f
STEP 14/19: RUN pip install --upgrade pip
--> Using cache 0d53bb72db0ecc0f762a9a1091356888e4a4b69b83821afc0c3c202c60d77827
--> 0d53bb72db0
STEP 15/19: RUN pip install jupyter numpy matplotlib rise
--> Using cache 584186569bbf3160ecd6f38af2c851331ca5b64b477c682f39eef4ea0bedcfe1
--> 584186569bb
STEP 16/19: RUN pip install future pillow onnx opencv-python-headless tensorflow onnxruntime
--> Using cache e99ace598bc7fbe7b941ff29f8dc2e4f95f63aeef003c7a5ef4cb859e6f8a26d
--> e99ace598bc
STEP 17/19: RUN pip install Cython && pip install pycocotools
--> Using cache 0828585156bbf3aaf0ed8711e09d30ce4d7943ce5a867fd4cb19b071bc3afe4b
--> 0828585156b
STEP 18/19: RUN cd /tmp &&     git clone --recursive https://github.com/mlcommons/inference &&     cd inference/loadgen &&     pip install pybind11 &&     CFLAGS="-std=c++14" python setup.py install &&     rm -rf mlperf
--> Using cache 74e31c79a830df8b8c24e5313157447efc5a10c851fcc55a337d88dea7f79605
--> 74e31c79a83
STEP 19/19: ENTRYPOINT ["/bin/bash"]
--> Using cache 48f87ddf24a7463447de38c3fdac570a607fa9452c079ebe072719a7e09e0eb7
COMMIT mlperf-infer-imgclassify-cpu
--> 48f87ddf24a
Successfully tagged localhost/mlperf-infer-imgclassify-cpu:latest
48f87ddf24a7463447de38c3fdac570a607fa9452c079ebe072719a7e09e0eb7
Clearing caches.
3
STARTING RUN AT 2022-02-24 03:46:57 PM
INFO:main:Namespace(accuracy=False, audit_conf='audit.config', backend='pytorch-native', cache=0, count=None, data_format=None, dataset='coco-300-pt', dataset_list=None, dataset_path='/home/ahalwai/mlperf-inference/coco2', debug=False, find_peak_performance=False, inputs=['image'], max_batchsize=32, max_latency=None, mlperf_conf='./mlperf.conf', model='/home/ahalwai/mlperf-inference/mlperf//ssd_mobilenet_v1.pytorch', model_name='ssd-mobilenet', output='/output', outputs=['bboxes', 'labels', 'scores'], performance_sample_count=None, profile='ssd-mobilenet-pytorch', qps=None, samples_per_query=8, scenario='SingleStream', threads=8, time=None, user_conf='user.conf')
INFO:coco:loaded 5000 images, cache=0, took=0.6sec
/mlperf/python/coco.py:115: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  self.label_list = np.array(self.label_list)
/opt/anaconda3/lib/python3.7/site-packages/torch/serialization.py:454: SourceChangeWarning: source code of class 'models.ssd_mobilenet_v1.SSD' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.
  warnings.warn(msg, SourceChangeWarning)
INFO:main:starting TestScenario.SingleStream
Mean latency: 62877908.22106918
TestScenario.SingleStream qps=15.89, mean=0.0629, time=600.241, queries=9540, tiles=50.0:0.0620,80.0:0.0638,90.0:0.0653,95.0:0.0680,99.0:0.0791,99.9:0.0950
ENDING RUN AT 2022-02-24 03:57:00 PM
